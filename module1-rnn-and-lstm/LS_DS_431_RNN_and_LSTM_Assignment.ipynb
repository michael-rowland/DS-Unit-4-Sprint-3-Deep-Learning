{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "4-2",
      "language": "python",
      "name": "4-2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cB_t_5Xbc_om"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YqUP9VnvBg6a",
        "outputId": "7ba0dbb6-c828-454d-a97f-747d7a322585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: unknown command \"upgrade\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "bcd05f92-5926-4843-d2ff-e2f1c7af7719"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DuSkRyRfi6q1",
        "colab": {}
      },
      "source": [
        "url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
        "\n",
        "data = []\n",
        "\n",
        "with requests.get(url) as raw_text:\n",
        "  raw_text.encoding = 'utf-8'\n",
        "  data.append(raw_text.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3cKy5sIbjVeO",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4cXpBxv225Bv",
        "outputId": "b24a9bef-d224-4565-f07b-e0cdd40823cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1148003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zlYJGtkL3LWl",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENt0F0Ys3cmR",
        "outputId": "3056a1d4-7f39-48ce-df91-05310ef8cc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1148003, 40, 108)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fbRzzxvq3fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "296246a0-89d2-445e-d8a2-627ed8344d82"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiRL1OIL323Q",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iysl76ZJ39VH",
        "colab": {}
      },
      "source": [
        "# def on_epoch_end(epoch, _):\n",
        "#     # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "#     print()\n",
        "#     print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "#     generated = ''\n",
        "    \n",
        "#     sentence = text[start_index: start_index + maxlen]\n",
        "#     generated += sentence\n",
        "    \n",
        "#     print('----- Generating with seed: \"' + sentence + '\"')\n",
        "#     sys.stdout.write(generated)\n",
        "    \n",
        "#     for i in range(400):\n",
        "#         x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "#         for t, char in enumerate(sentence):\n",
        "#             x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "#         preds = model.predict(x_pred, verbose=0)[0]\n",
        "#         next_index = sample(preds)\n",
        "#         next_char = int_char[next_index]\n",
        "        \n",
        "#         sentence = sentence[1:] + next_char\n",
        "        \n",
        "#         sys.stdout.write(next_char)\n",
        "#         sys.stdout.flush()\n",
        "#     print()\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    #sys.stdout.write(generated)\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "        # sys.stdout.write(next_char)\n",
        "        # sys.stdout.flush()\n",
        "    print(generated)\n",
        "    print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SmgqWUQe4BXd",
        "outputId": "876058eb-a790-4c91-b5e5-9adbc08f164f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1148003 samples\n",
            "Epoch 1/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 2.1927\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"he worst this letter doth contain?\n",
            "  GL\"\n",
            "he worst this letter doth contain?\n",
            "  GLEtG SEND. Vram.\n",
            "_IPKI\n",
            " fow or ilmer astald nap mage.\n",
            "\n",
            "DUSACLIA.\n",
            "It mor sive hatr yree ay to Lor wisl axing.\n",
            "\n",
            "HANTA.\n",
            "The thos oher solt, tho I'end Kish if that aispr_\n",
            "    Whing forserterald me matint nor bont]\n",
            "  BUPNYRUD] L’s har ful-kers jeit?\n",
            "S\n",
            "ATE t   ESOODEG, NTo bomy, the! Tall, be yor st no nfor and;\n",
            "    Mor the thanl sah at fron sh pil. mat fring, sher goths. Whald plote, mang di\n",
            "\n",
            "1148003/1148003 [==============================] - 79s 69us/sample - loss: 2.1927\n",
            "Epoch 2/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 2.0732\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ning Bear,\n",
            "And quench the guards of the\"\n",
            "ning Bear,\n",
            "And quench the guards of then whers eees\n",
            "Isther is imtalain.\n",
            "\n",
            "BORENDE.\n",
            "In! o  pounce, your tous with thay Deanal trongajus, Whald,\n",
            "Thou, wam mom edotere to ard mocd not to whak ir hems\n",
            "“nokn om tith on gout sens nist thoecen.\n",
            "  KONCO. Noe shees, af wond you couly you haltok'\n",
            "    Antiat tonithile, nossefed, deoves.\n",
            "    No, ditht it thy whyseale, how that thow sull,\n",
            "    I thy easser; whay serpousp in catlence,\n",
            "Haki \n",
            "\n",
            "1148003/1148003 [==============================] - 79s 68us/sample - loss: 2.0732\n",
            "Epoch 3/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 2.0041\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"ice his own\n",
            "To evil should be done by n\"\n",
            "ice his own\n",
            "To evil should be done by no wire. \n",
            "  SASTHBORS. Mant, aTh. Hestubt I lave lute that, Rove al knive,\n",
            "I dould sher bo lattac’s.y Cowis, of'As uther Me then\n",
            "And shate, le afiak, a ghy utlon, and-and\n",
            "  FFor Evincy ant comt, Milusers]\n",
            "\n",
            "HOCHON. He sis oue thaug.\n",
            "  TRAETHE. Gurge heakere, Fraush to.\n",
            "\n",
            "HOPIANIAS.\n",
            "You hist._]\n",
            "    Tel coup and Cravene it your angese\n",
            "As forsalt’s, pain, I sur i’ls your Pipsine neam andidg,\n",
            "\n",
            "1148003/1148003 [==============================] - 78s 68us/sample - loss: 2.0041\n",
            "Epoch 4/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.9527\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"\n",
            "                      [Music of the hau\"\n",
            "\n",
            "                      [Music of the haur.\n",
            "\n",
            "      IRSIACD. “its thou hever to effel domay dodgeant for Rom'd thom,\n",
            "un and med in lit sure, fut apers,\n",
            "whough prapor of the cay the lees. Eriat it peltions\n",
            "    Heree you inter de herp love my gooting thit heir.\n",
            "  HANDOMONGAR. Bat wibh gifen’d and fack and the clemsune!\n",
            "  DOS OF FRADAS. And and agether;\n",
            "    Romefors, as wouling lord. I an le is us.\n",
            "\n",
            "LOTHES.\n",
            "Or, thau ryate\n",
            "  MAwn \n",
            "\n",
            "1148003/1148003 [==============================] - 77s 67us/sample - loss: 1.9527\n",
            "Epoch 5/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.9108\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"s in ourselves that we are thus or thus.\"\n",
            "s in ourselves that we are thus or thus.\n",
            "\n",
            "ANTINES\n",
            "Them.\n",
            "\n",
            "LARVASW.\n",
            "For whis werenthnught\n",
            "Let offaight dut, to, and whis hene goost to lask\n",
            "Than oug. I ham hovise.\n",
            "Ho  praule trother enor way no the. What have heres Goice; hey, nice Canner-\n",
            "\n",
            "DERECASER.\n",
            "It his sor whoreng biliece of thou litht\n",
            "Uny. O Sake his me live nem preplnces\n",
            "    Ald at aro aurpers in this prorion\n",
            "Think stong-ig they digh, sourest no Cam'\n",
            "    Whon the \n",
            "\n",
            "1148003/1148003 [==============================] - 77s 67us/sample - loss: 1.9108\n",
            "Epoch 6/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.8769\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \" one\n",
            "    Coriolanus will carry it.\n",
            "  F\"\n",
            " one\n",
            "    Coriolanus will carry it.\n",
            "  FOOSPER. Whou hath sour.\n",
            "Ghe, fave aiven that un a great’d. If he was live trat\n",
            "anver rade hefot not; no delce en him hige he murk's of ese!\n",
            "  KACHUS. nove aI the warkine feny the heaght ham\n",
            "Or not a that that icomes-’sant.\n",
            "    Benglenst; LAJRON. Nay, that reasomf'tle werspal apio?\n",
            "  ALSTH [FFrESS. My andy.\n",
            "     mis the bettel swark to Sol, that I heve your heanver, sain?\n",
            "Wit live liven ste\n",
            "\n",
            "1148003/1148003 [==============================] - 77s 67us/sample - loss: 1.8769\n",
            "Epoch 7/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.8484\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"he comes not\n",
            "    To tell us whether the\"\n",
            "he comes not\n",
            "    To tell us whether the degh wiwt plain bedide.\n",
            "\n",
            "RERUS.\n",
            "Ay her, you have that on this have, and siet, and by\n",
            "    That I naine onmest thou gount her we blded!\n",
            "  DUMLENUS. Whet. How horr, Doaraive of excelob, I play:\n",
            "I’ she good suck, what same to woplt’s of gunce.\n",
            "\n",
            "TARTHIA.\n",
            "I bore thou daif of good\n",
            "       in the presser of here a ceese.\n",
            "    Some your agfors os ham’d fear be igford and their hoak the\n",
            "and not e\n",
            "\n",
            "1148003/1148003 [==============================] - 77s 67us/sample - loss: 1.8484\n",
            "Epoch 8/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.8231\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"be master of it. Wilt thou not, beast, a\"\n",
            "be master of it. Wilt thou not, beast, agen atsium\n",
            "Vot thy ford.                             Exeunt.\n",
            "\n",
            "CEEILEIE.\n",
            "      Betomed: Tamin mervilan ritheld.\n",
            "\n",
            "PRORE.\n",
            "Well ow the’ll mind; .ond bunteds of thy klew\n",
            "Is yit for ot? Welloke? I sauld thave with of: lothimes,\n",
            "    ful callalfurevactiou, than have tane\n",
            "Of thut himking ot thy nam, the\n",
            "    paid rith Lord not a borr, and um as a am.\n",
            "And neress ssen our come you shise; to Eall\n",
            "\n",
            "\n",
            "1148003/1148003 [==============================] - 77s 67us/sample - loss: 1.8231\n",
            "Epoch 9/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.8017\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ed tyrant to their sex?\n",
            "\n",
            "\n",
            "      CLAUD\"\n",
            "ed tyrant to their sex?\n",
            "\n",
            "\n",
            "      CLAUDED. There misty.\n",
            "  NOWACK. O then hope honk but ploodought's see maneruget?\n",
            "  HOSTZARUNMPE. At my hear a’lerblith,\n",
            "As d weld give I sauth or Therous to buce.\n",
            "  * Stood whally of onceselfing the foor crain fall\n",
            "Whuch liok a dich, and fringht aboft your all a gefe it:\n",
            "Remer, and to the rife a have your are gald by fathous,\n",
            "    Wark murus, the purio. I draviul of there\n",
            "So gess: their would ic\n",
            "\n",
            "1148003/1148003 [==============================] - 78s 68us/sample - loss: 1.8018\n",
            "Epoch 10/10\n",
            "1147904/1148003 [============================>.] - ETA: 0s - loss: 1.7825\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"atures children sweete,\n",
            "Ly fore Bride a\"\n",
            "atures children sweete,\n",
            "Ly fore Bride a wome the quin. Bu is my hopecalc.\n",
            "  CORTTRS. Poon for their untoor thinked mestrow\n",
            "    To heavain ulow's seavy that reaited?\n",
            "    Courkent your and withrem.\n",
            "\n",
            "BERRY.\n",
            "Thee, she in heart I’ll rest that a, Sween, As you gress, love,\n",
            "Thou hadduet Creac's love; whonkn him he vistayle and gore brake,\n",
            "That “  he pay his likenother of have most,\n",
            "For us netshes, lue here and ham! heaver\n",
            "If to this\n",
            "\n",
            "1148003/1148003 [==============================] - 78s 68us/sample - loss: 1.7825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98a38037f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}